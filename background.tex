\subsection{Binary Instrumentation}
Recording a log of events during the execution of an application is essential for better understanding the program behavior and, in case of a failure, to locate the problem. Recording this type of information requires instrumentation of the program either at the source-code or the binary-code level. Instrumenting the source code by adding extra statements to collect the desired information is easy for developers. However, doing so modifies the code and requires recompilation, often involving multiple different tools and complex hierarchies of makefiles, which can make this approach cumbersome and frustrating for users. Instrumenting an executable at the binary level using a tool is much easier, faster, and less error prone for most users. Moreover, binary instrumentation is language independent, portable to any system that has the appropriate instrumentation tool installed, and provides machine-level insight into the behavior of the application.

Executables can be instrumented \textit{statically}, where the additional code is inserted into the binary before execution, which results in a persistent modified executable, or \textit{dynamically}, where the modification of the executable is not permanent. In dynamic binary instrumentation, code can be discovered at runtime, making it possible to handle dynamically-generated and self-modifying code. Furthermore, it may be possible to attach the instrumentation to a running process, which is particularly useful for long-running applications.

Many different tools for investigating application behavior have been designed on top of such Dynamic Binary Instrumentation (DBI) frameworks. For instance, Dyninst~\cite{dyninst} provides a dynamic instrumentation API that gives developers the ability to measure various performance aspects. It is used in tools like Open-SpeedShop~\cite{openss} and TAU~\cite{tau} as well as correctness debuggers like STAT~\cite{stat}. Moreover, VampirTrace~\cite{vampirt} uses it to provide a library for collecting program execution logs. 

Valgrind~\cite{valgrind} is a shadow-value DBI framework that keeps a copy of every register and memory location. It provides developers with the ability to instrument system calls and instructions. Error detectors such as Memcheck~\cite{memcheck} and call-graph generators like \callgrind~\cite{callgrind} are built upon Valgrind.

We designed \parlot on top of \pin~\cite{pin}, a DBI framework for the IA-32, x86-64, and MIC instruction-set architectures for creating dynamic program analysis tools. \parlot mutates \pin to track the function call stack and to trace the entry (call) and exit (return) of every executed function.


\subsection{Efficient Tracing for Debugging}
When dealing with large-scale parallel programs, any attempt to capture reasonably frequent events will result in a vast amount of data. Moreover, transferring and storing the data will incur significant overhead. For example, collecting just one byte of information per executed instruction yields on the order of a gigabyte of data per second on a single high-end core. Storing the resulting multi-gigabyte traces from many cores can be a challenge, even on today's large hard disks.

Hence, we need a way to decrease the space and runtime overhead. Compression can encode the generated data using a smaller number of bits, help
reduce the amount of data movement across the memory hierarchy, and
and also reduce storage and network demands.
%
Although the encoded data will later have to be decoded for analysis, compressing them during tracing enables the collection of much more information.

We do not claim that the use of compression itself is new:
various performance evaluation tools~\cite{tau,scorep,eventflowgraph} 
employ compression during the collection
of performance analysis data.
%
Tools such as ScalaTrace~\cite{scalatrace}
are also known to exploit
the repetitive nature of time-step simulations~\cite{freitag}. 


The novelty offered by ParLoT lies in the combination of compression
speeds, compression efficacy, and low timing jitter
made possible by the design of ParLot and its {\em incremental}
compression algorithm, all of which is
described in \S\ref{sec:design}.
%
All traced information is immediately compressed while the application is running; that is, ParLoT
never even records uncompressed data in memory. 
%
As a result, typically just a few kilobytes of data need to be written per thread and per second, thus requiring only a small fraction of the available disk or network bandwidth. 
%
The traces are decompressed later at no additional cost to the execution of the application. 
%
From the decompressed full function-call trace, the complete call-graph, 
call-frequency, and caller-callee information can be extracted. 
%
This can be done at the granularity of a thread, a group of threads, or the whole application.
%
We now elaborate on the design of ParLoT that makes
these innovations possible.
%--






