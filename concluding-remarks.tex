
We introduce \parlot, a portable low overhead dynamic
binary instrumentation-based
tracing approach that can help with studying and debugging of parallel applications.}
%
The traces that \parlot produces are sufficiently informative that
a variety of debugging and performance analysis methods can be brought to bear on the
(efficiently collected) traces.
%
Key properties of \parlot include its on-the-fly trace collection and
compression (which reduces timing jitter), a plethora of information
about function calls and returns, and
significantly improved compression efficiencies.
%

In this paper, we present an evaluation of various tool versions of \parlot
created by disabling/enabling compression, not collecting any traces, etc.
%
In order to provide an intuitive comparison against a well known tool,
we also compare \parlot against \callgrind.
%
Our evaluation criteria cover tracing overhead, the required bandwidth,
the achieved compression ratio, initialization overhead, and the 
overall impact of compression.
%
Detailed evaluations on the NAS parallel benchmarks running on
up to 1024 cores establishes the merit of our tool and our design decisions. 
\parlot can collect more than 36 MB worth of data per core per second while 
only needing 56 kB/s of the system bandwidth and slowdown the 
application by 2.7x, on average.
%
In addition to efficiently supporting a variety of analyses, 
these results support 
our plans for building an ``always on'' 
trace collection scheme to permit debugging.


The traces collected by \parlot cut through the entire stack of heterogeneous
(MPI, OpenMP, PThreads) calls. 
%
This permits a designer to project these traces onto specific
APIs of interest during program analysis, visualization, and debugging.
%
We are also building a framework for debugging parallel
programs based on \parlot, relying on
methods to diff executions and detect outliers.


A number of improvements to \parlot remain to be made.
%
These include allowing users to selectively trace at specific
interfaces: doing so can further increase compression efficiency
by reducing the variety of function calls to be treated by
the compressor.
%
We also discuss the need to bring down initialization overheads, i.e.,
by switching to a less general-purpose DBI tool.
%
We are also researching similar methods to
other CPUs and GPUs that come with binary instrumentation and tracing
facilities similar to \pin.
%

%--end
