
Detecting and root causing HPC bugs is expensive. While traditional software engineering generally achieves high quality control, these methods are often inapplicable to HPC where concurrency combined with large problem scales and sophisticated domain-specific math can make programming very challenging. For example, it took months for scientists to debug an MPI laser-plasma interaction code~\cite{hpcdoe}.

HPC bugs may be a combination of both flawed program logic and unspecified or illegal interactions between various concurrency models (e.g., PThreads, MPI, OpenMP, etc.) that coexist in most large applications. Moreover, HPC software tends to consume vast amounts of CPU time and hardware resources. Reproducing bugs by rerunning the application is therefore expensive and undesirable. 
%The best hope for debugging lies in being able to efficiently capture detailed execution 
A natural and field-proven approach for large-scale debugging is to capture detailed execution traces and compare the traces against corresponding traces from previous (stable) runs~\cite{stat,cstg}.
%
A {\em key requirement} is to do this collection {\em as efficiently as possible}
and in {\em as general a manner} as possible.
%

Existing tools in this space
do not meet our criteria for efficiency and generality.
%
For example, in STAT~\cite{stat}, such ``tracing and diffing'' is usually only done
when a failure (e.g., a deadlock or hang) is encountered.
%
Whereas STAT can be deployed in ``continuous collection'' mode, the overheads of
doing so are unknown (and can be surmised to be significant).
%
In CSTG~\cite{cstg}, the collection is orchestrated by the
user around chosen collection points and employs heavy-weight
unix {\tt backtrace} calls.


The thrust of the work in this paper is to avoid many of the drawbacks of existing
tracing-based debugging methods.
%
We are interested in avoiding
source-code modifications and recompilation --- thus making binary
instrumentation-based tools the only practical and widely deployable option.
%
We also believe in the value
of creating tools that are {\em portable across a 
wide variety of platforms}.
%
Previous tools (e.g., STAT) rely on mechanisms such as
MRNet~\cite{mrnet} to accelerate the collection and aggregation of traces.
%
Our thrust is to not depend on such mechanisms for trace aggregation but to instead offer 
a generic and low-overhead tracing tool that 
(1)~collects many types of dynamic facts about executions (e.g., all function
calls and returns), 
(2)~is easy to install, 
(3)~and is portable to multiple parallel platforms.
%
{\em Providing all these features in a single tool
that operates based on binary instrumentation
is an unsolved problem.}
%
In this paper, we describe a new tracing approach that fulfills these requirements, which we implemented in our proof-of-concept \parlot tool.


\parlot is an efficient binary-level tracing tool that captures all function calls and returns, including in library code, 
to help locate a variety of possible bug types through 
offline analysis (without needing application reruns) 
if/when the application runs into an error. 
%
With \parlot, the user can easily build a host of post-processors to examine
executions from many vantage points.
%
For instance, they can write post-processors
to detect unexpected (or ``outlier'') executions.
%
If needed, they can 
drill down and detect abnormal behaviors {\em even in the runtime and
support library stack} such as MPI-level activities.
%
In HPC, it is well-known (especially on newer machines) that bugs are often due to
broken libraries (MPI, OpenMP) or broken runtime or OS-level activities.
%
Having a single low-overhead tool that can ``X-ray'' an application to this depth is a goal met by \parlot -- again a unique feature in today's tool eco-system.

To further motivate the need for full function call
traces, consider the expression {\tt f()+g()}.
%
In C, there is no sequence point associated with the {\tt +}
operator~\cite{sequence-points-in-C}.
%
If these function calls have inadvertent side-effects causing 
failure, it is important to know in which order {\tt f()}
and {\tt g()} were invoked---something that is easy to discern using
\parlot 's traces.


One may be concerned that such a tool introduces excessive execution slowdown.
%
\parlot goes to great lengths to minimize these overheads to a level that we believe most users will find acceptable. The mindset is to \textit{``pay a little upfront to dramatically reduce the number of overall debug iterations''}. 
%
This paper makes the following main contributions.
%
\begin{itemize}
\item It introduces a new tracing approach that makes it possible to capture the full call-return, call-stack, call-graph, and call-frequency information, including all library calls, for every thread and process of large-scale applications at low overhead in both space and time.
\item It describes advanced data compression methods to drastically reduce the required tracing bandwidth, thus enabling the collection of a rich set of information, which would be infeasible without on-the-fly compression.
\item It presents \parlot, a proof-of-concept tool that implements our compression-based low-overhead tracing approach. \parlot is capable of instrumenting x86 applications at the binary level (regardless of the source language used) to collect full function-call traces.
\end{itemize}
The remainder of this paper is organized as follows. Section \ref{sec:bgreltool} introduces the basic ideas and infrastructure behind \parlot and other tracing tools. Section \ref{sec:design} describes the design of \parlot in detail. Sections \ref{sec:evalmeth} and \ref{sec:results} present our evaluation of different aspects of \parlot and compare it with a similar tool. Section \ref{sec:concl}
concludes the paper with a summary and future work.
% that includes the construction of verification tools that exploit \parlot traces.


\ignore{--
\subsection{Key strong points of \parlot from results}

\begin{itemize}
\item \textsf{Low tracing overhead - Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} - Fig \ref{comet_chartAvg_sd_B_p3_5}, \ref{comet_chartAvg_sd_C_p3_5} - Section \ref{subsec:lowtoh}}
	\begin{itemize}
	\item \textsf{ On average, both \parlotm and \parlota has better performance than \callgrind and amount of informative data that \callgrind generates is smaller and less informative than other two. (bolded numbers in Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} - Input B : \parlotm 2.20 : , \parlota : 3.47, \callgrind : 3.82). For input size C the results are even better (next bullet) \textbf{Conclusion: \parlot performance beats \callgrind (on average). However, \callgrind scales better}}
	\item \textsf{By increasing the size of input, average of geometric means of overheads decreases for \parlotm and \parlota but increases for \callgrind. (bolded numbers in Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} - Input C : \parlotm 1.98 : , \parlota : 2.83, \callgrind : 4.88). \textbf{Conclusion: \parlot performs better on larger input sizes}}
	\end{itemize}
\item \textsf{ Low required bandwidth, low tracing overhead and high compression ratio for makes \parlot work perfect to solve the the trade-off between "more overhead to add, more information to get"-Table \ref{comet_bw_pMpAcg_BC_itn_p3.5} - Fig \ref{comet_chartAvg_bw_B_p3_5}, \ref{comet_chartAvg_bw_C_p3_5} - Section \ref{subsec:lowbw}}
	\begin{itemize}
	\item \textsf{ In addition to big gap between average overhead of \parlotm and \callgrind, \parlotm also beats \callgrind in required bandwidth, especially for smaller inputs.}
	\item\textsf{ \textbf{\parlota vs. \callgrind}: According to table \ref{comet_cr_pMpA_BC_itn_p3.5} (from next subsection), for \parlota where the average compression ratio for input C is 644.38, and the correspondent required bandwidth which is 56.38 kB/s, it shows that \parlota can collect \textbf{more than 36 MB} worth of data per core per second where it only needs \textbf{56.38 kB/s} bandwidth, while \callgrind can only collects \textbf{less than 100 kB} of informative data and still adds more overhead comparing to either \parlota or \parlotm. \textbf{Conclusion: The amount of informative data can be collected with \parlota  are 360x larger than \callgrind and the overhead \parlota adds is less than 0.6x smaller than \callgrind}}
	\item \textsf{\textbf{\parlotm vs. \callgrind} Above story is true also for \parlotm. According to table \ref{comet_cr_pMpA_BC_itn_p3.5}, for \parlotm where the average compression ratio for input C is 1117.01, and the correspondent required bandwidth which is 7.84 kB/s, shows that \parlotm can collect \textbf{more than 8.5 MB} worth of data per core per second where it only needs \textbf{7.84.38 kB/s} bandwidth, while \callgrind can only collects \textbf{less than 100 kB} of informative data and still adds more overhead comparing to either \parlota or \parlotm. \textbf{Conclusion: The amount of informative data can be collected with \parlotm  are 85x larger than \callgrind and the overhead \parlotm adds is about 0.4x smaller than \callgrind}}
	\end{itemize}
	
	
\item \textsf{High Compression Ratio Table \ref{comet_cr_pMpA_BC_itn_p3.5} - Fig \ref{comet_chartAvg_cr_B_p3_5}, \ref{comet_chartAvg_cr_C_p3_5} - Section \ref{subsec:cr}
\textbf{Conclusion: I included some interesting facts about the charts and table of Compression Ratio in previous section}}
\item \textsf{ Pin-init overhead - Table \ref{comet_wo_det_All_all_B_p3.5}, \ref{comet_wo_det_Main_all_B_p3.5} - Fig \ref{comet_chartDet_B_wc_byTool_p3_5}, \ref{comet_chartDet_C_wc_byTool_p3_5} - Section: \ref{subsec:pinit}}
	\begin{itemize}
	\item \textsf{\textbf{most of the added overhead by \parlot is caused by Pin-init}. According to tables \ref{comet_wo_det_Main_all_B_p3.5}, \ref{comet_wo_det_All_all_B_p3.5}, on average, Pin-init adds 3.28 overhead and \parlota adds 3.42 overhead. \textbf{almost 96\% of \parlota overhead is happening on Pin-init - Numbers from \parlotm and other inputs are following the same pattern}}
	\end{itemize}
\item \textsf{ \parlot without compression  (high impact of compression method on performance) - Table \ref{comet_wo_det_All_all_B_p3.5}, \ref{comet_wo_det_Main_all_B_p3.5}  - Fig \ref{comet_chartDet_B_woc_byTool_p3_5}, \ref{comet_chartDet_C_woc_byTool_p3_5} - Section \ref{subsec:compact}}

\begin{itemize}
\item \textsf{on average, \parlotnc slows down the application execution almost \textbf{2x} more than \parlota. (average overhead of geometric means of all overheads within table  \ref{comet_wo_det_All_all_B_p3.5} for \parlota is \textbf{3.42} and for its coresponding \parlotnc is \textbf{6.62}) . The numbers of \parlotm and input C is following the same pattern. For example, \parlot-nc slows down the application execution almost \textbf{1.66x} more than \parlotm)}
\end{itemize}
\end{itemize}

\vspace{1ex}

\vspace{1ex}
\noindent{\bf Ganesh note: Cite follow-on
tools such as AutomaDeD~\cite{automaded} and Prodometer~\cite{prodometer} somewhere.}
\vspace{1ex}
---}



