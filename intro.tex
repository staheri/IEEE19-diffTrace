
Detecting and root causing HPC bugs is expensive. While traditional software engineering generally achieves high quality control, these methods are often inapplicable to HPC where concurrency combined with large problem scales and sophisticated domain-specific math can make programming extremely challenging. For example, it took months for scientists to debug an MPI laser-plasma interaction code~\cite{hpcdoe}.

HPC bugs are typically a function of both flawed program logic as well as unspecified or illegal interactions between various concurrency models ({\em e.g.}, PThreads, MPI, OpenMP, etc.) that coexist in most large applications. Moreover, HPC software tends to consume enormous amounts of CPU time and hardware resources. Reproducing bugs by rerunning the application in case of execution failure is therefore expensive, time consuming, and inefficient. 
%The best hope for debugging lies in being able to efficiently capture detailed execution 
A very natural and field-proven~\cite{stat,cstg} approach to large-scale debugging is to
capture detailed execution traces
compare these traces
 against corresponding
 traces from previous (stable) runs.
%
A {\em key requirement} is to do this collection {\em as efficiently as possible}
and in {\em as general a manner} as possible.
%

Existing tools in this space
do not meet our criteria for efficiency and generality.
%
For example, in STAT~\cite{stat}, such ``tracing and diffing'' is often done
when a failure ({\em e.g.} a deadlock or hang) is encountered.
%
While STAT can be deployed in ``continuous collection'' mode, the overheads of
doing so are unknown (and can be surmised to be non-trivial).
%
In the context of CSTGs~\cite{cstg}, the collection is orchestrated by the
user around chosen collection points, and this approach also employs heavy-weight
unix {\tt backtrace} calls.


The thrust of the work in this paper is to avoid many of the drawbacks of existing
tracing-based debugging methods.
%
We are interested in avoiding
source-code modifications and recompilation --- thus making binary
instrumentation-based tools the only practical and widely deployable recourse.
%
We also believe in the value
of providing our tool in a manner that makes it {\em portable across a 
wide variety of platforms}.
%
Previous tools (e.g. STAT) have relied on  mechanisms such as
TBon~\cite{tbon-dorian} and MRNet~\cite{mrnet} to accelerate collection and
aggregation of traces.
%
Our thrust is to not rely on such mechanisms for trace aggregation, but
instead offer 
a generic and low-overhead tracing tool that 
(1)~collects many types of dynamic facts about executions (e.g., function
calls and returns), 
(2)~is easy to install, 
(3)~and is also portable to multiple parallel platforms.
%
As discussed in this paper, {\em providing all these features in a single tool
that operates based on binary instrumentation
is an unsolved problem.}
%
In this paper, we describe how we have arrived at such a solution that is embodied
in our ParLoT tool.


This paper presents \parlot, an efficient binary-level tracing tool that captures traces 
replete with debugging information to help locate a variety of possible bug types through 
offline trace analysis (without needing application reruns) 
if/when the application runs into an error. 
%
With ParLoT, the user can easily build a host of post-processors to examine
executions from many vantage points.
%
For instance, they can write post-processors
to detect unexpected (or ``outlier'') executions.
%
If needed, they can 
drill down and detect abnormal behaviors {\em even going deep into the runtime and
support library stack} such as MPI-level activities.
%
In HPC, it is well-known (especially on newer machines) that bugs are often due to
broken libraries (MPI, OpenMP) or broken runtime or OS-level activities.
%
Having a single tool that can ``X-ray'' to any depth is a goal met by ParLoT -- again
a unique feature in today's tool eco-system.


To further motivate the need for having full function call
traces for debugging, consider an expression {\tt f()+g()} in C.
%
In C, there is no sequence point associated with the {\tt +}
operator~\cite{sequence-points-in-C}.
%
If these function calls have inadvertent side-effects causing 
failure, it would be important to know the order in which {\tt f()}
and {\tt g()} were invoked---something possible to discern using
ParLoT-generated traces.


One may be concerned that a tracing tool introduces execution slowdown.
%
ParLoT goes to great lengths to minimize these overheads.
%
However, our 
 mindset  is \textit{``pay a little upfront to dramatically reduce the number of overall debug iterations''}. This paper makes the following main contributions.
\begin{itemize}
\item It introduces a new tracing approach that makes it possible to capture the full call-return, call-stack, call-graph, and call-frequency information, including all library calls, for every thread and process of even large-scale applications at low overhead in both space and time.
\item It describes advanced data compression methods to drastically reduce the required tracing bandwidth, thus enabling the collection of a rich set of information, which would be infeasible without on-the-fly compression.
\item It presents \parlot, a proof-of-concept tool that implements our compression-based low-overhead tracing approach. \parlot is capable of instrumenting any x86-based application at the binary level (regardless of the source language used) to collect its full function-call trace.
\end{itemize}
The remainder of this paper is organized as follows. Section \ref{sec:bgreltool} introduces the basic ideas and infrastructure behind \parlot and other tracing tools. Section \ref{sec:design} describes the design of \parlot in detail. Sections \ref{sec:evalmeth} and \ref{sec:results} present our evaluation of different aspects of \parlot and compare it with a similar tool. Section \ref{sec:???} concludes the paper with a summary and future work.


\subsection{Key strong points of \parlot from results}

\begin{itemize}
\item \textsf{Low tracing overhead - Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} - Fig \ref{comet_chartAvg_sd_B_p3_5}, \ref{comet_chartAvg_sd_C_p3_5} - Section \ref{subsec:lowtoh}}
	\begin{itemize}
	\item \textsf{ On average, both \parlotm and \parlota has better performance than \callgrind and amount of informative data that \callgrind generates is smaller and less informative than other two. (bolded numbers in Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} - Input B : \parlotm 2.20 : , \parlota : 3.47, \callgrind : 3.82). For input size C the results are even better (next bullet) \textbf{Conclusion: \parlot performance beats \callgrind (on average). However, \callgrind scales better}}
	\item \textsf{By increasing the size of input, average of geometric means of overheads decreases for \parlotm and \parlota but increases for \callgrind. (bolded numbers in Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} - Input C : \parlotm 1.98 : , \parlota : 2.83, \callgrind : 4.88). \textbf{Conclusion: \parlot performs better on larger input sizes}}
	\end{itemize}
\item \textsf{ Low required bandwidth, low tracing overhead and high compression ratio for makes \parlot work perfect to solve the the trade-off between "more overhead to add, more information to get"-Table \ref{comet_bw_pMpAcg_BC_itn_p3.5} - Fig \ref{comet_chartAvg_bw_B_p3_5}, \ref{comet_chartAvg_bw_C_p3_5} - Section \ref{subsec:lowbw}}
	\begin{itemize}
	\item \textsf{ In addition to big gap between average overhead of \parlotm and \callgrind, \parlotm also beats \callgrind in required bandwidth, especially for smaller inputs.}
	\item\textsf{ \textbf{\parlota vs. \callgrind}: According to table \ref{comet_cr_pMpA_BC_itn_p3.5} (from next subsection), for \parlota where the average compression ratio for input C is 644.38, and the correspondent required bandwidth which is 56.38 kB/s, it shows that \parlota can collect \textbf{more than 36 MB} worth of data per core per second where it only needs \textbf{56.38 kB/s} bandwidth, while \callgrind can only collects \textbf{less than 100 kB} of informative data and still adds more overhead comparing to either \parlota or \parlotm. \textbf{Conclusion: The amount of informative data can be collected with \parlota  are 360x larger than \callgrind and the overhead \parlota adds is less than 0.6x smaller than \callgrind}}
	\item \textsf{\textbf{\parlotm vs. \callgrind} Above story is true also for \parlotm. According to table \ref{comet_cr_pMpA_BC_itn_p3.5}, for \parlotm where the average compression ratio for input C is 1117.01, and the correspondent required bandwidth which is 7.84 kB/s, shows that \parlotm can collect \textbf{more than 8.5 MB} worth of data per core per second where it only needs \textbf{7.84.38 kB/s} bandwidth, while \callgrind can only collects \textbf{less than 100 kB} of informative data and still adds more overhead comparing to either \parlota or \parlotm. \textbf{Conclusion: The amount of informative data can be collected with \parlotm  are 85x larger than \callgrind and the overhead \parlotm adds is about 0.4x smaller than \callgrind}}
	\end{itemize}
	
	
\item \textsf{High Compression Ratio Table \ref{comet_cr_pMpA_BC_itn_p3.5} - Fig \ref{comet_chartAvg_cr_B_p3_5}, \ref{comet_chartAvg_cr_C_p3_5} - Section \ref{subsec:cr}
\textbf{Conclusion: I included some interesting facts about the charts and table of Compression Ratio in previous section}}
\item \textsf{ Pin-init overhead - Table \ref{comet_wo_det_All_all_B_p3.5}, \ref{comet_wo_det_Main_all_B_p3.5} - Fig \ref{comet_chartDet_B_wc_byTool_p3_5}, \ref{comet_chartDet_C_wc_byTool_p3_5} - Section: \ref{subsec:pinit}}
	\begin{itemize}
	\item \textsf{\textbf{most of the added overhead by \parlot is caused by Pin-init}. According to tables \ref{comet_wo_det_Main_all_B_p3.5}, \ref{comet_wo_det_All_all_B_p3.5}, on average, Pin-init adds 3.28 overhead and \parlota adds 3.42 overhead. \textbf{almost 96\% of \parlota overhead is happening on Pin-init - Numbers from \parlotm and other inputs are following the same pattern}}
	\end{itemize}
\item \textsf{ \parlot without compression  (high impact of compression method on performance) - Table \ref{comet_wo_det_All_all_B_p3.5}, \ref{comet_wo_det_Main_all_B_p3.5}  - Fig \ref{comet_chartDet_B_woc_byTool_p3_5}, \ref{comet_chartDet_C_woc_byTool_p3_5} - Section \ref{subsec:compact}}

\begin{itemize}
\item \textsf{on average, \parlotnc slows down the application execution almost \textbf{2x} more than \parlota. (average overhead of geometric means of all overheads within table  \ref{comet_wo_det_All_all_B_p3.5} for \parlota is \textbf{3.42} and for its coresponding \parlotnc is \textbf{6.62}) . The numbers of \parlotm and input C is following the same pattern. For example, \parlot-nc slows down the application execution almost \textbf{1.66x} more than \parlotm)}
\end{itemize}
\end{itemize}

\vspace{1ex}

\vspace{1ex}
\noindent{\bf Ganesh note: Cite follow-on
tools such as AutomaDeD~\cite{automaded} and Prodometer~\cite{prodometer} somewhere.}
\vspace{1ex}

