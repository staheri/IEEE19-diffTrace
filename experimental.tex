\begin{figure*}
     \centering
     \begin{subfigure}[b]{0.31\textwidth}
        \centering
\includegraphics[width=\textwidth]{figs/diffNLR/ompBug-6-4-x0.pdf}
\caption{diffNLR(6.4)}
\label{diffNLR-6-4}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.31\textwidth}
       \centering
\includegraphics[width=\textwidth]{figs/diffNLR/mpiBug-all-nn-x0.pdf}
\caption{diffNLR(0)}
\label{diffNLR-0}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.31\textwidth}
         \centering
\includegraphics[width=0.9\textwidth]{figs/diffNLR/mpiBug2-0-nn-x0.pdf}
\caption{diffNLR(5)}
\label{diffNLR-5}
     \end{subfigure}
        \caption{Three simple graphs}
        \label{fig:three graphs}
\end{figure*}

ILCS is a scalable framework for running iterative local searches on HPC platforms~\cite{ilcs}.
%
Providing serial CPU and/or single-GPU code, ILCS executes this code in parallel between compute nodes (MPI) and within them (OpenMP and CUDA).
%

To evaluate DiffTrace, we manually injected MPI-level and OMP-level bugs into the Traveling Salesman Problem (TSP) running on ILCS (Listing~\ref{lst:ilcs}).
%
The injected bugs simulate real HPC bugs such as deadlocks.
%
%These bugs are close to common mistakes that HPC developers usually make during developing HPC codes.
%
Moreover, we inserted ``hidden'' faults that do not crash the program such as violations of critical sections and semantic bugs. 
%
%The injected bugs are planted in a way that might get triggered in only one or more threads (master and worker threads, one thread, every other thread, all threads except one, all threads). 
%
The goal is to see how effectively DiffTrace can analyze the resulting traces and how close it can get to the root cause of the fault.
%
\input{tabs/ilcsPseudoCode-compact.tex}

%
We collected ParLoT (main image) traces from the execution of ILCS-TSP with 8 MPI processes and 4 OpenMP threads per process on the XSEDE-PSC Bridges supercomputer whose compute nodes have 128 GB of main memory and contain 2 Intel Haswell (E5-2695 v3) CPUs with 14 cores each running at 2.3 - 3.3 GHz.
%
Note that we did not provide any GPU code to ILCS.
%
The collected traces (faulty and normal) are fed to DiffTrace. We enabled the MPI, OpenMP, and custom (ILCS-TSP user code) filters and set the NLR constant K to 10 for all experiments.
%
We present the results in form of ranking tables that show which traces (processes and threads) DiffTrace considers ``suspicious''. Furthermore, we show diffNLRs for selected traces.



\subsection{ILCS-TSP Workflow}

The TSP code starts with a random tour and iteratively shortens it using the 2-opt improvement heuristic~\cite{2-opt} until a local minimum is reached. ILCS automatically and asynchronously distributes unique seed values to each worker thread, runs the TSP code, reduces the results to find the best solution, and repeats these steps until the termination criterion is met. It employs two types of threads per node: a \textit{master} thread (MPI process) that handles the communication and local work distribution and a set of \textit{worker} threads (OpenMP threads) that execute the provided TSP code. The master thread forks a worker thread for each detected CPU core.
%
Each worker thread continually calls
\texttt{CPU\_Exec()} to evaluate a seed and records the result (lines 14-20).
%
Once the worker threads are running, the master thread's primary job is to scan the results of the workers to find the best solution computed so far (i.e., the local champion). This information is then globally reduced to determine the current system-wide champion (lines 22-32).
%
ILCS terminates the search when the quality has not improved over a certain period (lines 33-34).



\subsection{OpenMP Bug: Unprotected Memory Access}

The memory accesses performed by the \texttt{memcpy} calls on lines 20 and 30 are protected by an OpenMP critical section.
%
Not protecting them results in a data race that might lead to incorrect final program output.
%
To simulate this scenario, we modified the ILCS source code to omit the critical section in worker thread 4 of process 6.

Table~\ref{tab:mc1-mc-6-4} lists the top suspicious traces that DiffTrace finds when injecting this bug.
%
Each row presents results for different filters and attributes.
%
For example, the filter ``11.mem.ompcit.cust.0K10'' removes all function returns and .plt calls from the traces and only keeps memory-related calls, OpenMP critical-section functions, and the custom function ``CPU\_Exec''.
%
The ``K10'' at the end of filter means that the filtered traces are converted into an NLR with $K$=10.
%
%\hl{I will remove two unnecessary columns from the tables (threshold and linkage function) to save space and add 2-3 sentences explaining what was them}
%
The bold numbers in the rightmost column of the table flag trace 6.4 (i.e., process 6, thread 4) as the trace that was affected the most by the bug.

The corresponding diffNLR(6.4) presented in Figure~\ref{diffNLR-6-4} clearly shows that the normal execution of ILCS (green and blue blocks) protects the \texttt{memcpy} while the buggy execution (green and red blocks) does not. Here, L0 represents \texttt{CPU\_Exec}, which is called multiple times in both the fault-free and the buggy version (the call frequencies are different due to the asynchronous nature of ILCS).
%


%\begin{figure}[]
%\centering
%\includegraphics[width=0.3\textwidth]{figs/diffNLR/ompBug-6-4.pdf}
%\caption{OpenMP Bug: diffNLR(6.4)}
%\label{diffNLR-6-4}
%\end{figure}



\subsection{MPI Bug: Deadlock Caused by Fault in Collectives}
By forcing only one of the processes (process 2) to invoke MPI\_Allreduce (line 24) with a wrong size, we have simulated a \textit{real deadlock}. 
%
Table~\ref{tab:ar1-ws-all-nn} shows that almost all processes are suspicious.
%
It turned out that ParLOT did not happen to capture function calls from all processes since the bug happens too early in the code. Thus except for process 1 and 4, all other traces are empty.
%
By looking at the diffNLR(1) (Figure~\ref{diffNLR-0}), we can see that both normal and the buggy trace of process $1$ are identical until an invocation of MPI\_Allreduce(). After that, normal trace hits the end of the program and terminates while the buggy process is waiting for the return from the actual point of fault (process 2) and never ends (i.e., deadlocks). 
%
diffNLRs of other processes look the same.
%

%\input{tabs/ar1-ws-all-nn.tex}

%\begin{figure}[]
%\centering
%\includegraphics[width=0.3\textwidth]{figs/diffNLR/mpiBug-all-nn.pdf}
%\caption{diffNLR(0)}
%\label{diffNLR-0}
%\end{figure}
%

\input{tabs/mc1-mc-6-4.tex}

\input{tabs/ar1-ws-all-nn.tex}

\subsection{MPI Bug: Wrong Collective Operation}
By changing the operation MPI\_MIN to MPI\_MAX in the input arguments of MPI\_Allreduce(), we have changed the semantics of ILCS. 
%
The execution of this variation terminated well, but the results might be corrupted.
%

The MPI\_Allreduce() in line 24 of Listing~\ref{lst:ilcs} broadcasts the best-calculated answer among all processes.
%
However, by the change that we made to ILCS, now the ``worst'' answer is getting stored.
%
We injected the bug only to process 0.
%
Among all suggested suspicious processes (Table~\ref{tab:ar1-wo-0-nn}), only process 5 (bold numbers) are making sense since their filters are more relevant to the aspect that we are interested (MPI-level activities) to study deeper.
%
Our observation from diffNLR(5) (Figure~\ref{diffNLR-5}) is that process 5, in comparison with its corresponding normal process, involves more in updating and broadcasting the champion among all traces.
%
Similar to the deadlock bug, this is another instance of  ``bug manifestation'' detection by DiffTrace.

\input{tabs/ar1-wo-0-nn.tex}

%\begin{figure}[]
%\centering
%\includegraphics[width=0.3\textwidth]{figs/diffNLR/mpiBug2-0-nn.pdf}
%\caption{diffNLR(5)}
%\label{diffNLR-5}
%\end{figure}



