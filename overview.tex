\begin{figure*}[]
\caption{DiffTrace Overview}
\includegraphics[width=0.95\textwidth]{figs/overview.png}
%\includegraphics[]{figs/overview.png}
%\includegraphics[]{figs/overv}
\label{fig.diffTraceOverview}
\end{figure*}

The general idea is to utilize ParLOT \cite{ parlot} traces for studying HPC application behaviors towards fault detection and localization.
%
%ParLOT
ParLOT collects whole-program function calls and returns via dynamic binary instrumentation \cite{pin}, and incrementally compresses them on-the-fly.
%
ParLOT instruments and encodes functions within the binary to unique integers at two major levels: \textit{main image} only contains functions from the source-code and included APIs and \textit{all images} that cover system and library functions as well.
%
Upon termination of the application, ParLOT flushes out per-thread trace files containing compressed sequence of executed function IDs.
%
The compression mechanism of ParLOT significantly reduces the time, memory and disk overhead, leaves the majority of the system bandwidth for the application. 
%
With the mindset of ``\textit{pay a little upfront to dramatically reduce the number of overall debug iterations}'', ParLOT well overcomes the challenge of whole-program \textit{trace collection} and leaves the \textit{trace analysis} for offline post-mortem analysis, saving HPC resources.
%

% Paragraph about DiffTrace, why we need it and what is our approach?
In this paper, we introduce DiffTrace, a tool-chain (figure \ref{fig.diffTraceOverview} that provides an infrastructure for \textit{iterative and configurable search space reduction} of HPC traces.
%
Considering a ``successful’’ termination of the application as \textit{normal behavior}, DiffTrace systematically reduces the search space to detect a \textit{abnormal behavior} when an application crashes, time outs or produces a corrupted answer.
%
Each abnormal behavior is a potential \em{error} cause or a manifestation of a \em{fault}.
%
However, faults in HPC applications may occur or influence the program behavior at different locations and granularities, due to high and hybrid level of parallelism.
%
Also typical HPC applications spend most of their execution time in a main loop until a convergence or over timesteps, and a fault may get  triggered or causing problems after some iteration.
%

\begin{figure}[]
\centering
\caption{Simplified MPI implementation of Odd/Even Sort}
\includegraphics[width=0.45\textwidth]{figs/oddEven.png}
\label{fig.oddEven}
\end{figure}

DiffTrace gives the HPC developers the capability of going through the pipeline of trace processing multiple times, each time putting a flash-light on various aspects of the applications' dynamic behavior, gradually collecting evidence about what went wrong that made the program fails.
%
The work-flow of DiffTrace starts with \textit{pre-processing} traces. ParLOT traces are highly compressed and often contain functions that might no be interesting from a certain point of analysis. DiffTrace decompresses and prunes traces (systemically), providing cleaner traces for later phases.  
%
Loops in source codes reflect themselves as a sequence of \textit{repetitive patterns}, resulting in often-long but redundant traces. A ``nested loop  recognition'' mechanism then mines loops from traces as ``\textit{a measure of progress}'' per thread, and also a loss-less abstraction to ease the rest of trace analysis.
%
The control flow of events in parallel architectures often follow a \textit{regular pattern} such as SPMD, odd-even and master/slave. This characteristic often makes all traces of a single execution tend to fall into just \textit{a few} ``conceptually/behaviorally equivalent classes''. Adapted from the work by Webber et al \cite{weberStructural}, we have applied \textit{formal concept analysis} (FCA)\cite{clbook} techniques to reduce the trace search space into a few classes of traces, and also using the \textit{concept lattice} (CL) data structure as the \textit{model} of execution for further analysis.
%
To reveal the impact of the fault, DiffTrace then measures the similarity between the equivalent classes of faulty traces against the corresponding bug-free traces.
%
The basic idea is to find out which traces (and consequently processes/threads) are falling into a different class (i.e., cluster) when the fault is introduced.
%
Based on the observed similarity of two clusterings, DiffTrace suggests top suspicious traces that are suffering the most the fault for further analysis, and clearly reflects the actual points of differences of the suspicious trace versus its corresponding normal trace.
%
During the rest of this section, we explain each component of diffTrace in details on collected traces (ParLOT-main) of execution of a MPI implementation of odd/even sort (figure \ref{fig.oddEven}) with 4, 8 and 16 processes. 
Odd/Even sort is a variant of the bubble-sort operates in two alternate phases: \textit{Phase-even} where even processes exchange (compare and swap) values with right neighbors and \textit{Phase-odd} where odd processes exchange values with right neighbors. The for loop in line 4 of \texttt{oddEvenSort()} iterates over phases of the algorithm and based on the phase, the appropriate partner for each rank is getting discovered by the function \texttt{findPtr()} (line 6). The odd/even ranks then exchange their chunks of data (lines 9-13) and a set of sort, merge and copy operations would be performed on received data by each rank (which are replaced by \texttt{...} in line 15 for simplicity).

According to MPI Standard , MPI\_Send is a \textit{blocking send} used the \textit{standard} communication mode in which MPI \textit{may} buffer outgoing messages and the send call may complete before a matching receive is invoked. On the other hand, buffer space may be unavailable, or MPI may choose not to buffer outgoing messages, for performance reasons. In this case, the send call will not complete until a matching receive has been posted, and the data has been moved to the receiver. So based on the MPI implementation, a swap of order in line 11-12 of figure \ref{fig.oddEvenDL} code might end up causing a deadlock. This section ends with showing that DiffTrace can extract evidences from traces to justify and locate the cause of such deadlocks and other faults.


\subsection{Pre-processing}
\input{tabs/filters.tex}
Using ParLOT decoder, each trace needs to get decompressed for further analysis.
Supporting the iterative approach of DiffTrace which is exploring different aspects of traces one at a time, corresponding function names of each function ID in traces are checked with some pre-defined (table \ref{tab:filters}) or custom regular expressions (i.e., \textit{filters}). In case of a match, DiffTrace would keep that function ID for later phases, otherwise that function ID would not be stored in the current iteration of DiffTrace.

Table \ref{tab:oddEvenPT} shows pre-processed traces ($T_i$) of odd/even sort execution with 4 processes. $T_i$ is the trace that stores dynamic function calls of process $i$.
\input{tabs/oddEvenPT.tex}


\subsection{Nested Loop Representation}
HPC applications often spend most of their times in \textit{loops}. Function calls within each loop body reflect themselves as \textit{repetitive patterns} in ParLOT traces, leaving often long traces of redundant entries. 
Inspired by ideas from detection of repetitive patterns in strings \cite{nakamura_fast_2013} and other data structures\cite{kmr}, we have adapted the Nested Loop Recognition (NLR) algorithm from Ketterlin et al\cite{Ketterlin-nlr} to detect repetitive patterns in ParLOT traces (details of NLR algorithm are in section XX). Detecting such patterns ``measures progress'' per trace and reflects the delayed or unfinished/broken loops, potentially caused by a fault.

For example, the loop in line 3 of \texttt{oddEvenSort()} (figure \ref{fig.oddEven}) iterates 4 times in execution with 4 processes. Thus each $T_i$ contains 4 consecutive occurrence of either \texttt{MPI\_Send() - MPI\_Recv()} (even $T$s) or \texttt{MPI\_Recv() - MPI\_Send()} (odd $T$s). By keeping only MPI functions and converting each $T_i$ to its equivalent NLR (Nested Loop Representation), table \ref{tab:oddEvenPT} can be reduced to figure \ref{tab:oddEvenPT-r}. \textbf{L0} (pair of MPI\_Send - MPI\_Recv) and \textbf{L1} (pair of MPI\_Recv - MPI\_Send) are two main body loops that have been detected among pre-processed filters. Note that, since first and last processes have only one-way communication with their neighbors, $T_0$ and $T_3$ iterates over the loop half of other processes.

\hl{connect this section to next}

\begin{figure}[]
\centering
\caption{Trace NLRs}
\includegraphics[width=0.45\textwidth]{figs/oddEvenPT-r.png}
\label{tab:oddEvenPT-r}
\end{figure}


\subsection{Hierarchical Clustering via FCA}
\begin{itemize}
	\item Introducing FCA with some backgrounds
	\item CL incremental construction
	\item Context sample from odd/even example 
	\item Actual CL from odd/even example
	\item Obtaining JSM from reduced CL via LCA
	\item JSM sample from odd/even example
	\item Hierarchical Clustering based on the obtained JSM provides insight about general behavior of the execution 
\end{itemize}



\input{tabs/tabs.sampleContext.tex}


\begin{figure}[t]
\centering
\scalebox{0.5}{
\includegraphics[width=3.4in]{figs/sampleCL.png}}
\caption{Sample Concept Lattice from Obj-Atr Context in table\ref{tab:sampleContext}}
\label{fig:sampleCL}
\end{figure}


\begin{figure}[]
\centering
\scalebox{0.8}{
\includegraphics[width=3.4in]{figs/oddEvenJSM.pdf}}
\caption{Pair-wise Jaccard Similarity Matrix (JSM) of MPI processes in Sample code}
\label{fig:jsm}
\end{figure}

\begin{figure}[]
\centering
\scalebox{0.8}{
\includegraphics[width=3.4in]{figs/oddEvenJSM2.pdf}}
\caption{Pair-wise Jaccard Similarity Matrix (JSM) of MPI processes in Sample code}
\label{fig:jsm}
\end{figure}

\clearpage

\subsection{Diffing}

\begin{figure}[]
\centering
\caption{A line change in oddEvenSort (left) that might cause a deadlock in oddEvenSort\_DL (right)}
\includegraphics[width=0.45\textwidth]{figs/oddEvenDL.png}
\label{fig.oddEvenDL}
\end{figure}

To clearly see what has changed in the actual (suspicious) trace of a faulty execution with its corresponding trace from the normal run, we have implemented a visualized version of 

\begin{itemize}
	\item Comparison of JSMs (i.e., hierarchical clusterings) would give insight about how a change (bug, library update, porting to new system) has changed the behavior of the program.
	\item Outlier detection via Diffing JSMs
	\begin{itemize}
		\item the method by Fowlkes to measure the similarity score of two clusterings
		\item detecting outlier(s) by detecting if an object (trace) falls into a different cluster 
		\item an illustration of the idea on odd/even - explaining a potential deadlock.
	\end{itemize}
	\item introducing \textit{gdiff}: bolds the actual points of differences in the outlier trace w.r.t. its corresponding normal trace
	\item sample gdiffs from odd/even example
	
\end{itemize}

\begin{figure}[]
\centering
\caption{(a) The legend of \textit{gdiff} and the list of loop structures (b) \textit{gdiff(5)} of \textit{swapBug} (c) \textit{gdiff(5)} of \textit{dlBug}}
\includegraphics[width=0.45\textwidth]{figs/sampleGdiff.png}
\label{fig.gdiffs}
\end{figure}



\subsubsection{Ranking Suspicious Traces}
\begin{itemize}
	\item Select a set of parameters and let DiffTrace generate JSMs based on the parameters (from both buggy and bug-free).
	\item Calculate B-score and outliers for all possible combinations of parameters
	\item sort outliers (i.e., suggestions as suspicious traces that suffer the most from the change) based on their B-score, lower scores shows bigger change in JSMs, higher chance of showing the actual outlier.
\end{itemize}

``Diff'' algorithm by Meyers \cite{diff-myers} takes two sequences $S_A$ and $S_B$ and computes the minimal \textit{edit} to convert $S_A$ to $S_B$. This algorithm has been used in GNU \texttt{diff} to compare two text files and in git for efficiently keeping track of file changes.
Since ParLOT preserves the order of function calls in the binary, each per thread trace $T_i$ is totally ordered, thus \textit{diff} can reflect the differences of a pair of $T$s. \textit{gdiff} is the graphical visualization of diff, aligning common and different blocks of a pair of sequences horizontally and vertically, making it easier for analyst to see the differences of a pair of sequences in a glance.  
For simplicity, our implementation of \textit{gdiff} only takes one argument $x$ as \textit{the suspicious trace}

\textit{gdiff}$(x) \equiv $ \textit{gdiff}$(T_x,T_x^\prime)$

where $T_x$ is the trace of thread/process $x$ of a normal/successful execution and $T^\prime_x$ is the corresponding trace of faulty execution.



The for loop in line 4 of \texttt{oddEvenSort()} iterates over phases of the algorithm and based on the phase, the appropriate partner for each rank is getting discovered by the function \texttt{findPtr()} (line 6). The odd/even ranks then exchange their chunks of data (lines 9-13) and a set of sort, merge and copy operations would be performed on received data by each rank (which are replaced by \texttt{...} in line 15 for simplicity).
\\

Execution of odd/even sort application with four processes (\texttt{mpirun -np 4}) while ParLOT trace collection is enabled on top of the application, would result in $T_0$, $T_1$, $T_2$ and $T_3$ (table \ref{tab:oddEvenPT}). This execution terminates successfully with expected results and the set of generated traces clearly reflects the expected behavior (control flow) of odd and even processes.
%


 
%


%
We have planted two artificial bugs (\textit{swapBug} and \textit{dlBug}) in the code in figure \ref{fig.oddEven} and launched the code with 16 processes.
%
\textit{swapBug} swaps the order of MPI\_Send and MPI\_Recv in rank 5 after 7th iteration (of the loop in line 3 of \texttt{oddEvenSort}) simulating a potential deadlock and \textit{dlBug} simulates an actual deadlock (e.g., infinite loop) in the same location (rank 5 after 7th iteration).
%
Upon collection of ParLOT traces from execution above buggy versions, DiffTrace first decompresses traces and filters out all non-MPI functions.
Then two major loops are detected, \textbf{L0} and \textbf{L1}  (figure \ref{fig.gdiffs}-(a)) that are supposed to occur 16 times in even and odd ranks, respectively.
After analysis of CL models of execution, $x=5$ has been suggested as the most affected trace by the artificial bugs.
Figure \ref{fig.gdiffs}-(b) shows the 
\textit{gdiff}$(5)$ of \textit{swapBug} where $T_5$ iterates over the loop [MPI\_Recv - MPI\_Send] for 16 times (L1\^{}16) after the MPI initilization while the order swap has well reflected in $T_x^\prime$ (L1\^{}7 - L0\^{}9). Both processes seem to be terminated fine by executing MPI\_Finalize(). 
However, \textit{gdiff}$(5)$ of \textit{dlBug} (figure \ref{fig.gdiffs}-(c)) shows that while $T_5$ have executed MPI\_Finalize and terminated well, $T_5^\prime$ got stuck after executing L1 seven times and have never reached MPI\_Finalize.

This example shows that our approach can locate the impacted part of each execution by a fault. Having a pre-understanding of \textit{how the application should behave normally} would reduce the number of iterations by picking the right set of parameters on each pass. 





%
%In the remainder of this section, we describe a chain of techniques that we apply to collected traces with having three main goals in mind:
%\begin{itemize}
%\item selectively pre-processing of traces to prune out uninteresting trace entries when we want to study a certain aspect of the dynamic behavior of the application. 
%\item reducing the search space by forming ``equivalent classes of traces'' and locating the trace or set of traces that got impacted the most by the fault.
%\item visualizing and reflecting the impact of fault to the potential faulty trace with respect to its corresponding fault-free trace.  
%\end{itemize}